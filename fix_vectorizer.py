"""
Script untuk reconstruct TF-IDF vectorizer dari model yang sudah ada
Jadi model tidak perlu di-train ulang, cukup generate vectorizer yang match
"""

import xgboost as xgb
import pickle
from sklearn.feature_extraction.text import TfidfVectorizer
import numpy as np

print("üîß Reconstructing TF-IDF Vectorizer from Model...")
print("="*70)

# 1. Load model yang sudah ada
print("\n1Ô∏è‚É£ Loading existing model...")
model = xgb.Booster()
model.load_model('models/xgb_osint_enhanced.json')
print("   ‚úÖ Model loaded")

# 2. Extract feature names dari model
print("\n2Ô∏è‚É£ Extracting feature names from model...")
feature_names = model.feature_names
print(f"   ‚úÖ Total features: {len(feature_names)}")

# 3. Filter hanya TF-IDF features (yang dimulai dengan 'tfidf_')
print("\n3Ô∏è‚É£ Extracting TF-IDF vocabulary...")
tfidf_features = [f for f in feature_names if f.startswith('tfidf_')]
print(f"   ‚úÖ TF-IDF features: {len(tfidf_features)}")

# 4. Extract vocabulary dari feature names (remove 'tfidf_' prefix)
vocabulary = {}
for idx, feature_name in enumerate(tfidf_features):
    word = feature_name.replace('tfidf_', '')
    vocabulary[word] = idx

print(f"   ‚úÖ Vocabulary size: {len(vocabulary)}")
print(f"   üìù Sample words: {list(vocabulary.keys())[:10]}")

# 5. Create TF-IDF vectorizer dengan vocabulary yang sama
print("\n4Ô∏è‚É£ Creating new TF-IDF vectorizer with matching vocabulary...")
tfidf = TfidfVectorizer(
    vocabulary=vocabulary,  # Fixed vocabulary from model
    lowercase=True,
    strip_accents='unicode',
    ngram_range=(1, 2),
    stop_words='english'
)

# Fit dengan dummy data (karena vocabulary sudah fixed)
# Vectorizer perlu di-fit dulu sebelum bisa dipakai
dummy_data = list(vocabulary.keys())
tfidf.fit(dummy_data)

print("   ‚úÖ Vectorizer created")

# 6. Verify vocabulary matches
print("\n5Ô∏è‚É£ Verifying vocabulary matches...")
reconstructed_words = tfidf.get_feature_names_out()
if len(reconstructed_words) == len(vocabulary):
    print(f"   ‚úÖ Vocabulary size matches: {len(vocabulary)} words")
else:
    print(f"   ‚ö†Ô∏è Vocabulary size mismatch: expected {len(vocabulary)}, got {len(reconstructed_words)}")

# Sample verification
print(f"   üìù First 10 words: {list(reconstructed_words[:10])}")
print(f"   üìù Last 10 words: {list(reconstructed_words[-10:])}")

# 7. Save vectorizer
print("\n6Ô∏è‚É£ Saving reconstructed vectorizer...")
with open('models/tfidf_vectorizer.pkl', 'wb') as f:
    pickle.dump(tfidf, f)
print("   ‚úÖ Saved to: models/tfidf_vectorizer.pkl")

# 8. Test load
print("\n7Ô∏è‚É£ Testing load...")
with open('models/tfidf_vectorizer.pkl', 'rb') as f:
    test_tfidf = pickle.load(f)
test_words = test_tfidf.get_feature_names_out()
print(f"   ‚úÖ Loaded successfully: {len(test_words)} words")

print("\n" + "="*70)
print("‚úÖ SUCCESS! TF-IDF vectorizer reconstructed and saved.")
print("   Model: models/xgb_osint_enhanced.json")
print("   Vectorizer: models/tfidf_vectorizer.pkl")
print("\nüí° Now restart your API and try prediction again!")
